import torch
from transformers import AutoTokenizer, AutoModel
from faiss import IndexFlatIP
import argparse

def do_add_doc(docs):
    model_name = 'bert-base-uncased'  # 替换为所需的Hugging Face模型的名称

    # 加载tokenizer和model
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModel.from_pretrained(model_name)

    # 将tokenizer和model作为embeddings返回
    embeddings = [tokenizer, model]

    # 创建faiss向量索引
    index = faiss.IndexFlatIP(model.config.hidden_size) # 使用内积作为相似度度量

    for doc in docs:
        # 将文档内容转化为向量表示
        with torch.no_grad():
            input_ids = tokenizer.encode(doc.content, return_tensors='pt')
            vector = model(input_ids)[0]

        # 添加文档到向量库
        index.add(vector.numpy())

    # 返回faiss向量索引对象
    return index

def do_search(index, query):
    # 将查询内容转化为向量表示
    with torch.no_grad():
        input_ids = tokenizer.encode(query, return_tensors='pt')
        vector = model(input_ids)[0]

    # 在向量索引中搜索相似文档
    D, I = index.search(vector.numpy(), 10)

    # 返回相似文档的内容
    results = []
    for i in I[0]:
        results.append(documents[i].content)

    return results

# 加载文档内容
documents = [
    {'content': '这是第一篇文档'},
    {'content': '这是第二篇文档'},
    {'content': '这是第三篇文档'}
]

# 加载预训练模型
model_name = 'bert-base-uncased'  # 替换为所需的Hugging Face模型的名称
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

# 创建命令行解析器
parser = argparse.ArgumentParser(description='Add documents to a vector database and search for similar documents.')
parser.add_argument('--add-documents', type=str, help='Path to a file containing the documents to add to the database.')
parser.add_argument('--vector-database', type=str, help='Path to the directory containing the vector database.')
args = parser.parse_args()

# 加载文档内容
with open(args.add_documents, 'r') as f:
    for line in f:
        doc = json.loads(line)
        documents.append(doc)

# 创建faiss向量索引
index = do_add_doc(documents)

# 在向量索引中搜索相似文档
query = '这是一篇文档'
results = do_search(index, query)

# 输出搜索结果
print(results)
